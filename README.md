# ğŸ•µï¸ Fraud Detection â€” EDA & Anomaly Analysis

## ğŸ“Œ DescripciÃ³n del proyecto
Este proyecto aborda el problema de **detecciÃ³n de fraude en transacciones financieras** mediante:

- AnÃ¡lisis exploratorio de datos (EDA)
- DetecciÃ³n de anomalÃ­as y outliers
- Modelos supervisados y no supervisados
- AnÃ¡lisis de comportamiento a nivel de usuario

El objetivo es **identificar patrones anÃ³malos y seÃ±ales de fraude**, priorizando enfoques **explicables y reproducibles**.

---

## ğŸ“Š Dataset
**Archivo:** `fraud_detection_transactions.csv`  
**Observaciones:** 50,000  
**Variables:** 21  

### Variables principales
- `Transaction_Amount`
- `Account_Balance`
- `Transaction_Distance`
- `Risk_Score`
- `Timestamp`
- `Fraud_Label` (variable objetivo)

Incluye informaciÃ³n transaccional, histÃ³rica, contextual y de comportamiento del usuario.

---

## ğŸ§ª Estructura del proyecto

proyecto-analisis-outliers/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Dataset original
â”‚ â”œâ”€â”€ processed/ # Dataset enriquecido tras EDA
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_eda.ipynb
â”‚ â”œâ”€â”€ 02_anomaly_detection.ipynb
â”‚ â”œâ”€â”€ 03_modeling.ipynb
â”‚ â””â”€â”€ 04_user_analysis.ipynb
â”‚
â”œâ”€â”€ src/ # CÃ³digo reutilizable
â”‚
â”œâ”€â”€ requirements.txt / pyproject.toml
â””â”€â”€ README.md


---

## ğŸ” AnÃ¡lisis Exploratorio de Datos (EDA)

### Outliers clÃ¡sicos
- Detectados mediante el mÃ©todo **IQR**
- Solo `Transaction_Amount` mostrÃ³ outliers univariados relevantes (~4.5%)

### AnomalÃ­as contextuales
Se creÃ³ la variable:

amount_vs_avg_7d = Transaction_Amount / Avg_Transaction_Amount_7d


Resultados:
- Percentil 99 â‰ˆ **8.6Ã—**
- MÃ¡ximo â‰ˆ **61Ã—**
- SeÃ±al altamente informativa para fraude

---

## ğŸ§  Feature Engineering

Se generaron seÃ±ales explicables:

- `flag_amt_vs_avg_p99`
- `flag_far_distance`
- `flag_high_risk`
- `flag_night_tx`

Y un score agregado:

fraud_score_simple = suma de flags


### Resultados clave
| Fraud Score | % Fraude |
|------------|----------|
| 0 | 24.7% |
| 1 | 42.5% |
| 2 | 88.7% |
| 3 | 100% |

---

## ğŸ¤– Modelado

### Logistic Regression (supervisado)
- Features numÃ©ricas + flags + score
- Escalado con `StandardScaler`

**Resultados:**
- ROC AUC â‰ˆ **0.95**
- Recall fraude â‰ˆ **90%**
- Modelo interpretable

### Isolation Forest (no supervisado)
- ~10% de transacciones detectadas como anÃ³malas
- **79.8%** de fraude dentro de anomalÃ­as
- Ãštil cuando no hay etiquetas

---

## ğŸ‘¤ AnÃ¡lisis por Usuario

AgregaciÃ³n por `User_ID`:
- Tasa de fraude
- Severidad (`fraud_score_simple`)
- Reincidencia

Hallazgos:
- Usuarios con **100% de fraude**
- Usuarios con mÃºltiples transacciones de alto score
- Evidencia clara de *bad actors*

---

## â±ï¸ AnÃ¡lisis Temporal

Se analizaron rÃ¡fagas de transacciones (â‰¤10 minutos entre operaciones).

Resultado:
- Las rÃ¡fagas **no presentan mayor tasa de fraude**
- El fraude se distribuye en el tiempo â†’ comportamiento mÃ¡s sigiloso

---

## ğŸ§¾ Conclusiones

1. Los outliers clÃ¡sicos no capturan completamente el fraude.
2. Las anomalÃ­as contextuales son mÃ¡s informativas.
3. Los modelos supervisados superan a los no supervisados cuando existen etiquetas.
4. Un enfoque explicable puede lograr alto desempeÃ±o.
5. El fraude no siempre ocurre en rÃ¡fagas temporales.

---

## âš™ï¸ TecnologÃ­as

- Python 3.11
- pandas, numpy, matplotlib
- scikit-learn
- Poetry + Conda
- Jupyter Lab

---

## ğŸš€ PrÃ³ximos pasos

- OptimizaciÃ³n de umbrales segÃºn costo de error
- Modelos avanzados (XGBoost, LightGBM)
- Monitoreo en tiempo real
- Explicabilidad con SHAP

---

## âœï¸ Autor
**Juan Sebastian Angel Perez**  
Proyecto de anÃ¡lisis de datos y detecciÃ³n de fraude para la clase de Big Data



